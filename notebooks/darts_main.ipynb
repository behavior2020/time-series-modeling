{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darts Time Series Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts_config import *\n",
    "from darts_models import (\n",
    "    NaiveSeasonalGrowth\n",
    ")\n",
    "\n",
    "from darts_functions import (\n",
    "    create_csv,\n",
    "    full_series_backtesting,\n",
    "    full_series_backtesting_nn,\n",
    "    count_zeroes,\n",
    "    plot_models,\n",
    "    custom_backtest,\n",
    "    Optimizer,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import rmse\n",
    "from darts.models import (\n",
    "    ExponentialSmoothing,\n",
    "    NaiveDrift,\n",
    "    NaiveMean,\n",
    "    NaiveMovingAverage,\n",
    "    NaiveSeasonal,\n",
    "    NHiTSModel,\n",
    "    Prophet,\n",
    "    StatsForecastAutoCES,\n",
    "    StatsForecastAutoETS,\n",
    "    StatsForecastAutoTheta,\n",
    "    TiDEModel,\n",
    "    RegressionEnsembleModel,\n",
    "    NaiveEnsembleModel\n",
    ")\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sales data\n",
    "file_path = file_name\n",
    "raw_df = pd.read_excel(file_path)\n",
    "\n",
    "# Get the index of the forecast date\n",
    "FORECAST_DATE = raw_df[\"Forecast Date\"][0]\n",
    "end_col = raw_df.columns.get_loc(FORECAST_DATE)\n",
    "\n",
    "# Get the index of the first date column\n",
    "start_col = 0\n",
    "for index, value in enumerate(raw_df.columns):\n",
    "    try:\n",
    "        pd.to_datetime(value, format=\"%d/%m/%Y\")\n",
    "        start_col = index\n",
    "        break\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "df = raw_df.copy()\n",
    "df = df.iloc[:, start_col:end_col]  # slice dataset to include only relevant dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns, format=\"%d%m%Y\")  # convert date columns to datetime and transpose dataframe\n",
    "df.set_index(raw_df[\"Item Code\"], inplace=True)  # set item code as index\n",
    "df = df.T  # transpose dataframe\n",
    "df.columns = df.columns.astype(str)  # convert item names to string\n",
    "df.dropna(axis=1, inplace=True)  # drop all columns with at least one NaN value\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:].clip(lower=0)  # clip negative values to zero\n",
    "df = df.loc[\n",
    "    :, (df == 0).sum(axis=0) <= (ZEROS_MAX_PERCENT * df.shape[0])\n",
    "]  # drop columns with more than n percent of zeros\n",
    "df.replace(0, np.nan, inplace=True)  # replace zeros with NaN\n",
    "df.interpolate(method=\"linear\", axis=1, inplace=True)  # interpolate missing values column wise\n",
    "df.fillna(method=\"ffill\", inplace=True)  # forward fill missing values\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check for date range\n",
    "print(f\"Actual sales dates range from {df.index[0]} to {df.index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check for no zero or nan values\n",
    "print(f\" Number of Zeros: {count_zeroes(df)}\\n Number of NaNs: {(df.isna().sum().sum())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of series\n",
    "all_series = [TimeSeries.from_dataframe(df, value_cols=col) for col in df.columns]\n",
    "\n",
    "# Scale data for improved modeling\n",
    "scaler = Scaler()\n",
    "all_series_scaled = [scaler.fit_transform(series) for series in all_series]  # scale each series object\n",
    "\n",
    "# Set train window of backtesting\n",
    "TRAIN_WINDOW = len(df) - VAL_WINDOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose what to run\n",
    "RUN_StatModels = \"Yes\"\n",
    "GET_StatModels_results = \"Yes\"\n",
    "\n",
    "RUN_DeepLearning = \"Yes\"\n",
    "GET_DeepLearning_results = \"Yes\"\n",
    "\n",
    "RUN_ExSmoothing_NHITS = \"Yes\"\n",
    "PLOT_NHiTS = \"Yes\"\n",
    "PLOT_Loop = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our Naive Seasonal Growth model\n",
    "baseline_model = NaiveSeasonalGrowth(K=SEASONALITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statisical Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose statistical models for testing\n",
    "stat_models = [\n",
    "    (StatsForecastAutoETS, {\"season_length\": SEASONALITY}),\n",
    "    (StatsForecastAutoCES, {\"season_length\": SEASONALITY}),\n",
    "    (StatsForecastAutoTheta, {\"season_length\": SEASONALITY}),\n",
    "    (ExponentialSmoothing, {\"seasonal_periods\": SEASONALITY}),\n",
    "    (NaiveSeasonal, {\"K\": SEASONALITY}),\n",
    "    (NaiveDrift, {}),\n",
    "    (NaiveMovingAverage, {\"input_chunk_length\": SEASONALITY}),\n",
    "    (NaiveMean, {}),\n",
    "    (\n",
    "        Prophet,\n",
    "        {\n",
    "            \"add_seasonality\": {\n",
    "                \"name\": \"monthly\",\n",
    "                \"seasonal_periods\": DAYS_PER_MONTH,\n",
    "                \"fourier_order\": FOURIER_ORDER,\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit statistical models using backtesting\n",
    "if RUN_StatModels == \"Yes\":\n",
    "    stat_results, stat_instances = full_series_backtesting(\n",
    "        model_list=stat_models,\n",
    "        data=df,\n",
    "        series_list=all_series,\n",
    "        file_path=file_path,\n",
    "        train_percentage=TRAIN_WINDOW,\n",
    "        prediction_length=FORECAST_PERIODS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model results\n",
    "if GET_StatModels_results == \"Yes\":\n",
    "    create_csv(stat_results, file_path, \"stat__results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of times a model won\n",
    "results = {}\n",
    "for index, row in stat_results.iterrows():\n",
    "    item = row[0]\n",
    "    subset = stat_results[stat_results[\"Item\"] == item]\n",
    "    optimizer = Optimizer(subset)\n",
    "    model = optimizer.get_best_model(column_name=\"RMSE\")\n",
    "    results[item] = model\n",
    "\n",
    "model_counts = Counter(results.values())\n",
    "model_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest Validation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that number of backtest predictions is 3\n",
    "NUM_PLOTS = 1\n",
    "for series in all_series[:NUM_PLOTS]:\n",
    "    model = NaiveMean()\n",
    "    forecast = custom_backtest(model=model, series=series, train_window=TRAIN_WINDOW, forecast_hoizon=FORECAST_PERIODS)\n",
    "\n",
    "    baseline_forecast = custom_backtest(\n",
    "        model=baseline_model, series=series, train_window=TRAIN_WINDOW, forecast_hoizon=FORECAST_PERIODS\n",
    "    )\n",
    "\n",
    "    plot_models(model=model, series=series, forecast=forecast, baseline_forecast=baseline_forecast, label=\"forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather subsetted data and optimized models for specified SKU\n",
    "SKU_INDEX = 30\n",
    "series = all_series[SKU_INDEX]\n",
    "if RUN_StatModels == \"Yes\":\n",
    "    stat_subset = stat_results[stat_results[\"Item\"] == series.columns[0]]\n",
    "    stat_optimizer = Optimizer(stat_subset)\n",
    "    stat_model = stat_optimizer.get_best_model(column_name=\"RMSE\")\n",
    "\n",
    "stat_subset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive ensembling simply takes the average (mean) of the forecasts generated by the ensembled forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ensemble models against best model\n",
    "\n",
    "if RUN_StatModels == \"Yes\":\n",
    "    NUM_PLOTS = 40\n",
    "    baseline_model = NaiveSeasonalGrowth(K=12)\n",
    "    for series in all_series[:NUM_PLOTS]:\n",
    "        # Retrieve winning model for series\n",
    "        item = series.components[0]\n",
    "        subset = stat_results[stat_results[\"Item\"] == item]\n",
    "        optimizer = Optimizer(subset)\n",
    "\n",
    "        # Initialize fitted ensemble model\n",
    "        best_model = optimizer.get_best_model(column_name=\"RMSE\")\n",
    "        winning_model = stat_instances[best_model]\n",
    "        print(\"Winning Model:\", best_model)\n",
    "\n",
    "        ensemble_models = [winning_model, baseline_model]\n",
    "        naive_ensemble_model = NaiveEnsembleModel(forecasting_models=ensemble_models)\n",
    "        regression_ensemble_model = RegressionEnsembleModel(\n",
    "            forecasting_models=ensemble_models, regression_train_n_points=SEASONALITY\n",
    "        )\n",
    "\n",
    "        # Predictions\n",
    "        winning_model_forecast = custom_backtest(\n",
    "            model=winning_model,\n",
    "            series=series,\n",
    "            train_window=TRAIN_WINDOW,\n",
    "            forecast_hoizon=FORECAST_PERIODS,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        naive_ensemble_forecast = custom_backtest(\n",
    "            model=naive_ensemble_model,\n",
    "            series=series,\n",
    "            train_window=TRAIN_WINDOW,\n",
    "            forecast_hoizon=FORECAST_PERIODS,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        regression_ensemble_forecast = custom_backtest(\n",
    "            model=regression_ensemble_model,\n",
    "            series=series,\n",
    "            train_window=TRAIN_WINDOW,\n",
    "            forecast_hoizon=FORECAST_PERIODS,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Calculate RMSE\n",
    "        rmse_winning_model = rmse(series, winning_model_forecast)\n",
    "        rmse_naive_ensemble = rmse(series, naive_ensemble_forecast)\n",
    "        rmse_regression_ensemble = rmse(series, regression_ensemble_forecast)\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        series[-16:].plot(label=item)\n",
    "        winning_model_forecast.plot(label=f\"Winning Model (RMSE: {rmse_winning_model:.2f})\")\n",
    "        naive_ensemble_forecast.plot(label=f\"Naive Ensemble (RMSE: {rmse_naive_ensemble:.2f})\")\n",
    "        regression_ensemble_forecast.plot(label=f\"Regression Ensemble (RMSE: {rmse_regression_ensemble:.2f})\")\n",
    "        plt.title(\"Ensemble Model Testing\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish callbacks for deep learning models\n",
    "pl_trainer_kwargs[\"callbacks\"] = [EarlyStopping(**early_stopping_args)]  # callbacks need to be passed as a list\n",
    "\n",
    "# Add extra parameter to TiDEModel\n",
    "tide_model_args = common_model_args.copy()\n",
    "tide_model_args.update(\n",
    "    {\n",
    "        \"use_reversible_instance_norm\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Choose deep learning models for testing\n",
    "deep_learning_models = [\n",
    "    (\n",
    "        NHiTSModel,\n",
    "        common_model_args,\n",
    "    ),  # DARTS configues the model and training parameters (number of layers,nodes, and type of layers (convolutional for NHiTS))\n",
    "    (TiDEModel, tide_model_args),\n",
    "]  # 100% of terminal output from pytorch lightning, which executes the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit deep learning models\n",
    "if RUN_DeepLearning == \"Yes\":\n",
    "    nn_results, nn_instances = full_series_backtesting_nn(\n",
    "        model_list=deep_learning_models,\n",
    "        data=df,\n",
    "        series_list=all_series,\n",
    "        file_path=file_path,\n",
    "        train_percentage=TRAIN_PERCENTAGE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv with deep learning results\n",
    "if GET_DeepLearning_results == \"Yes\":\n",
    "    create_csv(nn_results, file_path, \"nn_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Winnning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit naive ensemble model against baseline model\n",
    "\n",
    "if RUN_DeepLearning == \"Yes\":\n",
    "    NUM_PLOTS = 5\n",
    "    scaler = Scaler()\n",
    "    baseline_model = NaiveSeasonalGrowth(K=SEASONALITY)\n",
    "    for series in all_series[:NUM_PLOTS]:\n",
    "        # Retrieve winning model for series\n",
    "        item = series.components[0]\n",
    "        subset = nn_results[nn_results[\"Item\"] == item]\n",
    "        optimizer = Optimizer(subset)\n",
    "        series_scaled = scaler.fit_transform(series)\n",
    "\n",
    "        best_model = optimizer.get_best_model(column_name=\"RMSE\")\n",
    "        model = nn_instances[best_model]\n",
    "        print(\"Winning Model:\", best_model)\n",
    "\n",
    "        forecast = custom_backtest(\n",
    "            model=model,\n",
    "            series=series_scaled,\n",
    "            train_window=TRAIN_WINDOW,\n",
    "            forecast_hoizon=FORECAST_PERIODS,\n",
    "            retrain=False,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        baseline_forecast = custom_backtest(\n",
    "            model=baseline_model,\n",
    "            series=series_scaled,\n",
    "            train_window=TRAIN_WINDOW,\n",
    "            forecast_hoizon=FORECAST_PERIODS,\n",
    "            retrain=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        forecast = scaler.inverse_transform(forecast)  # inverse scaled predictions\n",
    "        baseline_forecast = scaler.inverse_transform(baseline_forecast)  # inverse scaled predictions\n",
    "\n",
    "        # Calculate RMSE\n",
    "        rmse_winning_model = rmse(series, forecast)\n",
    "        rmse_baseline = rmse(series, baseline_forecast)\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        series[-16:].plot(label=item)\n",
    "        forecast.plot(label=f\"Neural Network (RMSE: {rmse_winning_model:.2f})\")\n",
    "        baseline_forecast.plot(label=f\"NaiveGrowthSeasonal (RMSE: {rmse_baseline:.2f})\")\n",
    "        plt.title(\"Deep Learning Testing\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-HiTS vs. Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an SKU to forecast\n",
    "SKU_NAME = \"ADR-7001\"\n",
    "SKU_INDEX = df.columns.get_loc(SKU_NAME)\n",
    "\n",
    "# Create series\n",
    "series = all_series[SKU_INDEX]\n",
    "seres_scaled = all_series_scaled[SKU_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "train_series, val_series = series[:-FORECAST_PERIODS], series[-FORECAST_PERIODS:]\n",
    "print(f\"Training set includes {len(train_series)} months & Validation set includes {len(val_series)} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "if RUN_ExSmoothing_NHITS == \"Yes\":\n",
    "    model_es = ExponentialSmoothing(seasonal_periods=SEASONALITY)\n",
    "    model_es.fit(train_series)  # fit on scaled training series\n",
    "    model_nh = nn_instances[\"NHiTSModel\"]  # fit on scaled training series\n",
    "\n",
    "    # Predict forecasting periods for each model\n",
    "    pred_es = model_es.predict(FORECAST_PERIODS)\n",
    "    pred_nh = model_nh.predict(FORECAST_PERIODS, series=train_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Sort standard deviation for each series to find a stable series for plotting\n",
    "if RUN_ExSmoothing_NHITS == \"Yes\":\n",
    "    std_devs = {}\n",
    "    for i, series in enumerate(all_series):\n",
    "        series_df = series.pd_dataframe()\n",
    "        std_dev = series_df.std().iloc[0]\n",
    "        std_devs[f\"Series {i}\"] = std_dev\n",
    "\n",
    "    sorted(std_devs.items(), key=lambda item: item[1], reverse=False)[:5]  # top 10 series by lowest standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaled data\n",
    "if PLOT_NHiTS == \"Yes\":\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    series[-36:].plot(label=\"actual sales\")  # scaled series\n",
    "    pred_nh.plot(label=\"n-hits forecast\", lw=3)  # scaled series\n",
    "    plt.legend()\n",
    "    plt.title(\"Sales Forecasting Comparison\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for each model\n",
    "if RUN_ExSmoothing_NHITS == \"Yes\":\n",
    "    hits_metric = METRIC(pred_nh, val_series)\n",
    "    es_metric = METRIC(pred_es, val_series)\n",
    "\n",
    "    print(f\"N-HiTS {METRIC_NAME} = {hits_metric:.2f}\")\n",
    "    print(f\"Exponential Smoothing {METRIC_NAME} = {es_metric:.2f}\")\n",
    "    print(f\"Improvement = {((es_metric - hits_metric) / es_metric) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all series to compare forecasting models\n",
    "if PLOT_Loop == \"Yes\":\n",
    "    for i, item_series in enumerate(all_series_scaled):\n",
    "        train_series, val_series = item_series[:-FORECAST_PERIODS], item_series[-FORECAST_PERIODS:]\n",
    "        print(\n",
    "            f\"Processing SKU {i}: Training set includes {len(train_series)} months & Validation set includes {len(val_series)} months\"\n",
    "        )\n",
    "\n",
    "        # Fit models\n",
    "        pred_nh = model_nh.predict(FORECAST_PERIODS, series=train_series)\n",
    "\n",
    "        # You might need to fit the model inside the loop if it requires retraining for each series\n",
    "        model_es.fit(train_series)\n",
    "        pred_es = model_es.predict(FORECAST_PERIODS)\n",
    "\n",
    "        # Plotting\n",
    "        item_series.plot(label=\"Actual sales\", lw=2)  # Original series\n",
    "        pred_nh.plot(label=\"N-HiTS forecast\", lw=2)\n",
    "        # pred_tide.plot(label=\"TiDE forecast\", lw=2)\n",
    "        pred_es.plot(label=\"Exponential Smoothing forecast\", lw=2)\n",
    "        plt.legend()\n",
    "        plt.title(f\"Sales Forecasting Comparison for SKU {i}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Scaled Sales\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-hSmJqVug-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
